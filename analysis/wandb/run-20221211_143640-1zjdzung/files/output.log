C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  train[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:29: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:29: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:29: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:29: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test[i]=s_s
C:\Users\aitbudapest\AppData\Local\Temp\ipykernel_19716\2930816559.py:29: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead
See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  test[i]=s_s
            Sales_USD
Date
2017-11-11  -0.652536
2017-11-12  -0.652981
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_1 (InputLayer)           [(None, 10, 4)]      0           []
 lstm (LSTM)                    [(None, 4),          144         ['input_1[0][0]']
                                 (None, 4),
                                 (None, 4)]
 repeat_vector (RepeatVector)   (None, 5, 4)         0           ['lstm[0][0]']
 lstm_1 (LSTM)                  (None, 5, 4)         144         ['repeat_vector[0][0]',
                                                                  'lstm[0][1]',
                                                                  'lstm[0][2]']
 time_distributed (TimeDistribu  (None, 5, 1)        5           ['lstm_1[0][0]']
 ted)
==================================================================================================
Total params: 293
Trainable params: 293
Non-trainable params: 0
__________________________________________________________________________________________________
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
12/12 [==============================] - 1s 2ms/step
[[[-0.4320107 ]
  [-0.43659148]
  [-0.4513216 ]
  [-0.47250247]
  [-0.4975939 ]]
 [[-0.4154573 ]
  [-0.42103332]
  [-0.43620515]
  [-0.4576686 ]
  [-0.4832549 ]]
 [[-0.41655457]
  [-0.41862392]
  [-0.43213618]
  [-0.45377827]
  [-0.48111135]]
 ...
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]]
[[[-0.31002327]
  [-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]]
 [[-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]]
 [[-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]
  [-0.33889113]]
 ...
 [[ 5.59819131]
  [ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]]
 [[ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]]
 [[ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]
  [ 6.01041249]]]
(353, 5, 1)
(353, 5, 1)
(353, 5, 1)
(353, 5, 1)
[-0.3100232741467599, -0.2667664651190923, -0.22132785223122087, -0.20472602411791418, -0.22859063172978156]
-0.3100232741467599
-0.2667664651190923
-0.22132785223122087
-0.20472602411791418
-0.22859063172978156
-0.2723040025293193
-0.3388911304183291
-0.3132625997840497
-0.2708777889067383
-0.2135315112347521
-0.18396640225893812
-0.23018126084293766
-0.202827305565076
-0.20797676465290948
-0.24120433561710297
-0.22607084389477916
-0.2318206262707413
-0.24394099018242965
-0.2698596738321585
-0.2738495182332109
-0.29495980646210884
-0.27572069765889706
-0.24538115369755176
-0.25026156642190134
-0.2417204133684283
-0.18177019286016605
-0.12656740174061332
-0.14309404232266787
-0.13408428033509923
-0.14721324715397743
-0.16662220654793303
-0.18409105038907647
-0.18105409689220164
-0.2156470059823845
-0.18708198512138807
-0.16087115519036388
-0.07082226272419034
-0.01964120380665224
-0.031403202860003754
-0.007136204891082354
-0.007141822546499643
-0.014707617042503784
0.04109287183481225
0.3672679561123706
0.584885993304725
0.5495359519045344
0.6683558632458804
0.7769257752814556
0.7639360417181544
0.8085274780327372
0.8739124172731039
0.7458221233217368
0.579024967993798
0.5569079795880254
0.7199084220945275
0.7293222960984065
0.7880186024867044
0.7517911278359886
0.7425972002546375
0.9991392356762892
0.9597252487701522
0.9255003057570366
0.7607600360367621
0.7614479591288661
0.9439441445293406
1.0518054794984955
0.9157056007257185
0.9038157833144949
0.8863240206266001
0.9942134379360859
0.9547615849156381
0.9199072403832345
0.9123821186029661
1.1634254801037178
1.3384389395831042
1.3804075007463505
1.4803295465383575
1.453322452169786
1.3816690243033887
1.5012266814778434
1.568568497217556
1.5844985264682054
1.5545806688052828
1.6359407507055637
1.6511486151393706
1.616345179774331
1.5950864177290556
1.581265814377161
1.6245283301115867
1.767360505093031
1.796515253616786
1.8955692892743174
1.8035097125202908
1.7473985977242683
1.5172829914665464
1.4127585452995062
1.3522635294666898
1.1872288500768744
1.1366231132835272
1.0527057395760528
1.2000903111204653
1.2444906076370894
1.3227823038855604
1.2821055229565888
1.1706790190414784
1.3506048680975176
1.4423539109525563
1.597107249417196
1.6458727862621432
1.654413396102437
1.609910916140588
1.6034969428548536
1.749167414117859
1.7389773834691926
1.6772601587621252
1.5701959965541938
1.603974341156289
1.6170754972414256
1.6060181807425224
1.655757716627802
1.5795357694531789
1.5626386263150325
1.4337227151199916
1.45645968638157
1.2864952227198598
1.4007946267833886
1.4451740882546367
1.4388807780515385
1.600069466576279
1.635373489211907
1.7642946559202453
1.8254688974975442
2.0679807071635543
2.056864870576024
2.0054987421935944
2.050962176658533
2.0661573586972173
2.039388690388585
1.977540837753843
1.9943973987117838
2.134093066734061
2.086888536073743
2.138133640715606
2.314313689085949
2.509134513268843
2.649508863822424
2.654389367082303
2.5799269957404705
2.384125649506529
2.252502433583911
2.3549977158256863
2.5351273885589958
2.79321937889388
2.494069414460466
2.387510369267993
2.367244811668889
2.6377393458675282
2.8456080615602297
2.9659527455798105
3.026055153345362
3.0232092505951047
3.2538314239209503
3.303478923761293
3.993843500856008
4.103002776928035
4.129535190545253
4.214777137643264
4.176773057575012
4.736126792165841
4.782276156457037
5.103178766124538
5.074587110007499
5.347888052686738
4.85842164860299
5.063912979944002
5.001827063391438
4.630350061518373
4.198257563285104
4.160706784225459
3.9758817697168802
3.31572855608352
3.234186935604011
2.56003574615809
2.4122527707883155
2.839972419256188
2.955648937001343
3.194901221217584
3.1607898750632093
2.971720283308944
2.6831571251942123
2.542529128222355
2.904177362926235
2.939623609458303
3.031130964005951
3.1645039719873806
3.113908924323311
3.055015318752648
2.9451204711844174
3.0961276453370528
2.7631663620742235
2.769436119681861
2.7618477684812253
2.5770024621404493
2.5054838283202883
2.654110719500089
2.7417742560353773
2.790450293314412
2.664887395150932
2.5202481755194683
2.4015420421079234
2.2549338082793584
2.2504334117626796
2.2268070491396914
1.8315611015734565
1.9063206016191039
1.8897109815134745
1.8680717520670678
1.61935178605844
1.81196734283701
2.0492109345470553
2.2012413872678493
2.2617224517239363
2.2489709631495147
2.072647787011621
2.194307803860937
2.4120676093037043
2.3195076263501497
2.3556803848886814
2.4409893668676896
2.322600652507967
2.1168466167431292
2.123893252311415
2.097963426854759
2.090626909877613
1.9021102660981555
1.864135535867653
1.8977303501088638
1.7818949410246434
1.7194129745704942
1.824402317714907
1.7172165855848518
1.5997875582308017
1.8798278633426015
1.9071904239483657
2.033828416686855
2.135062354958463
2.1302963539126236
2.4781589527577754
2.3121272634611563
2.3489761695361566
2.4301228265404355
2.538844020478003
2.659740564561843
2.8738620053090593
2.8297838386601883
2.77721869037266
2.9762920648646225
3.0890712245105987
3.2441283927924505
3.5785553839475193
3.5998895145951066
3.6015179192870437
3.665693513119342
3.72546002219566
3.676637957043743
3.807776347783101
3.8146175315187683
3.800967776132635
3.82161380113287
3.7545549816491826
3.5113903959711057
3.599639492566403
3.7685565803671257
3.7820700931385445
3.730689830824136
3.880075121811362
3.8582634132754685
3.6950605986285523
3.6964378933812365
3.7442069665009377
3.74866750512165
3.7462774398590244
3.8402940741834564
4.019006954926045
4.5679717285621155
4.558835052087783
4.843439889976118
4.7647474344943195
4.779200159883963
4.763230272737349
4.728927243571837
4.155744027210432
4.161489824538892
4.086654955890934
3.8402129068546675
4.0122925936574205
3.9589121551133766
3.9628712011082032
4.239098125955941
4.325222758849394
4.200542547965549
4.128563003699707
3.9912968981780925
3.835462124682976
3.4768406070243416
3.458118301740883
3.583475384445436
3.56284421469304
3.2798844489392676
3.496372403837839
3.5688121327809337
3.282520189040976
3.2470641602191175
3.3949460567866656
3.815467244571082
4.01580884521767
4.045148755226036
3.971191138757541
4.129518885244748
4.2498860354334305
4.290644706491239
4.317277492843088
4.258325186112739
4.221231693109203
4.249497594968917
4.136978601783554
4.227905832855551
4.5418368119307715
4.654943538028856
4.754364634408157
4.683783764637745
4.644172659620303
4.637819561831158
5.058651645656683
5.353435643993345
5.051977868052452
5.064872484394424
5.085748965359594
5.161349843252053
5.239216864045426
5.254090640500596
5.245182607796414
5.486488696443928
5.443615345458253
5.395529215428848
5.370108855661462
5.700527883435997
5.796943642512796
5.710275845418513
5.65740885909543
5.598191311462228
5.761340499391697
6.030633840832522
nan
nan
-0.3934783168405081
-0.5573820648967879
-0.8820702681508207
-1.0099408157240994
-0.8196231623564632
-0.5376712886663796
-0.2564942236308625
-0.416225887163699
-0.6722707203364742
-1.1239218009940952
-1.4307544008792212
-1.0425849355704149
-1.3166311342549468
-1.3049025889067687
-0.9522769910241909
-1.0880244871876
-1.0245002812729238
-0.8782885700233773
-0.6823107743031297
-0.6868570749766482
-0.5783379299278453
-0.7534168006988411
-0.9953881224169795
-0.93229613208344
-1.0103550506281045
-1.6587630775334383
-2.7913132710602504
-2.3229869130550114
-2.5456292299638594
-2.1590321643653128
-1.6901771958868976
-1.4333210505830305
-1.3772220731931235
-0.9846950067576861
-1.2647452174387797
-1.5580668536908966
-4.728430156919477
-19.278991588431463
-11.679792229584374
-55.777849609938755
-57.17550781884578
-27.92537606064995
11.77860669475146
2.2183018948283344
1.753128530653258
1.7994675856317264
1.6257818340856265
1.4734237411211062
1.4603778508265097
1.4076788920888061
1.357880258670786
1.3539775129299862
1.4572571310142848
1.466490529136823
1.3530944388914647
1.3543997480222014
1.357720971109199
1.4236676477170669
1.426385954273022
1.3031028018574304
1.3145095116579264
1.3377570626408577
1.3837755140194021
1.3547629902961476
1.2112353377477534
1.1485083101322693
1.14051396621706
1.104322876206276
1.0374877744017568
1.015554990070677
0.9824272102318045
0.9304646082337029
1.0242491386065202
1.095535855996353
1.087234208189258
1.028072082318587
1.0038800906075833
0.9653162016689766
0.9453438562953215
0.9327002783008559
0.9527146810910432
0.9368064159677135
0.9082466699706149
0.9319605917768985
0.9097194186754993
0.9412950946863881
1.0443350828115716
1.0563928181112467
1.092714829847172
1.1017433030107446
1.1037863161418975
1.1055839919755457
1.0948135000875512
1.1167635939430607
1.1359989417175245
1.0933705173541657
1.1092820888840345
1.086927693583841
1.0896020485834774
1.1547861676210793
1.1152434392121064
1.146857577736166
1.1442931477298801
1.139099572949883
1.1273478833353838
1.1154013654315602
1.0667744084456232
1.0794159057240755
1.108072053305488
1.1116811191460014
1.1104242512077898
1.122631512062082
1.1180387248571515
1.1180599909040196
1.123293224485794
1.1208360277819207
1.1183139167612255
1.1230160039152826
1.122266642478539
1.0976324121078065
1.1202306383721818
1.1304334790252026
1.1236646451535541
1.09676381096376
1.1085863868197974
1.0593102637271543
1.0639169095232262
1.0777989051975512
1.075535614661246
1.082294468262757
1.0864426639672824
1.0702252960211809
1.0574474089894519
1.0356618501176036
1.0345693113529406
1.022808771121517
1.0409467399735906
1.023161195669182
1.0217557829538526
1.0947578284671775
1.091314467224291
1.075063235699523
1.0931983379982426
1.073903186270961
1.0695920087386046
1.0778810591509438
1.074989490283583
1.0787748323407065
1.0655746291316408
1.0505194861762366
1.0479294258256264
1.032466164765955
1.0306527701327137
1.0303599602465614
1.033273246563871
1.0198727618236576
0.9946229837340093
1.002187231183802
1.0513453562855315
1.0345675672659258
1.0212776342850471
1.0321135057618764
1.0548065904888204
1.0475494426546315
1.0474406636778326
1.0489887872963701
1.0507690314849387
1.0487851495460705
1.0306253328163428
1.0393269631765207
1.0376205282515838
1.0301564843587385
1.0268073405470166
1.0412190431966408
1.0415732856927726
1.0413924330021487
1.0381088306352662
1.0346674974926169
1.0170933019630586
1.017767745748975
0.9994634008053125
0.9861995244469579
0.9807315324015207
1.010557211171514
0.9912919745909492
0.9974494372000311
0.9906660659584973
0.9876729798655379
1.0174756854747236
1.0182703903726849
1.0135900154036144
1.0025442268639013
0.9972702912525053
1.014573481492737
0.998450696736642
0.9865579639195975
0.9776997558671994
0.9695080271700999
0.9817790508476459
1.0072585034608963
1.005259942026128
0.9921721064616025
0.9964997989308391
1.0632323958003944
1.0171574730435422
0.9932750405813464
0.9866361504162825
1.0428310403730994
1.0397871668471312
1.0355146811287057
1.0409402753376267
1.0633242604802617
1.090407637765057
1.1111745828930597
1.0654517696715047
1.0664417050150585
1.0634173687755186
1.113473604528116
1.1030282468588188
1.093760438978356
1.0831551951412108
1.0703278347487482
1.0890444264474817
1.0869724835554047
1.0729812179976133
1.0372695951332143
1.0643771089703236
1.0551581097294536
1.0591181574846897
1.0796954629432238
1.09322301996002
1.0887159892069305
1.094569637888769
1.0907478444342795
1.0999076454495729
1.1082489211417845
1.0913367053770011
1.1144796520071931
1.1204018692000477
1.1133129527921166
1.118206024808547
1.1254231214807515
1.1036235392751548
1.1005377689947256
1.0850031670038
1.0862858329699738
1.0749775840623714
1.0708722497919712
1.0883196767718857
1.079781417070113
1.0757782386835317
1.0765978538573815
1.0738736559752875
1.06791893262981
1.0690118379249585
1.0719050179157612
1.0660475216247394
1.0632266051916566
1.0602169205963163
1.054555381957875
1.0543175461398326
1.0542168573966189
1.0532721093588864
1.0524481744681016
1.0532026351305968
1.0514139079814406
1.0513252095089147
1.0514639702385313
1.051167628868614
1.052246393128821
1.0559737887971794
1.0545103093867236
1.0523006772590833
1.0516364876262776
1.0523293524795199
1.0503168406242553
1.050596234648331
1.0528309646577305
1.0528114088109046
1.0521380877741078
1.0520754881923806
1.0521087115233703
1.0508330211785344
1.048572633039487
1.0427354279846595
1.0428210998905638
1.0403049954831456
1.0409711990770274
1.0408508155483884
1.0409985206689496
1.0413292884449645
1.047224086051879
1.047279357012662
1.0481910585720284
1.0517745317920093
1.0495293147423779
1.0511344786516876
1.0494070129349333
1.0466574717411754
1.0453404029741604
1.0464833157148077
1.0475874900695648
1.0490713767577806
1.0516028519954606
1.0568148608213537
1.0568244615528835
1.05577785168669
1.0548582151608439
1.059723382156942
1.0559526184681345
1.0547344119915936
1.0594758861148734
1.0601282785760064
1.0575305535292172
1.0511689413178258
1.0486262876836712
1.0482825214898295
1.0491704707736416
1.0472735237386792
1.0459376865727916
1.0455255390112164
1.0452273636940892
1.0458462518248464
1.0464215941970827
1.0459362260665277
1.0471976749396663
1.046201878411319
1.0430094295926557
1.0420281673504512
1.0410681332771543
1.0417078864642189
1.042123281800142
1.0421250592985172
1.0385902583437174
1.0364716254190418
1.0387357677137457
1.0385549759564987
1.0383858649118392
1.0378597770819065
1.037298318046114
1.0374313207462265
1.0372195661154302
1.0360849995175367
1.0359314035318392
1.0361808149451237
1.0363725726048874
1.0343950185175708
1.0336815889185045
1.034389153982101
1.0350015438454598
nan
nan
nan
nan
nan
-0.3934783168405081
-0.5573820648967879
-0.8820702681508207
-1.0099408157240994
-0.8196231623564632
-0.5376712886663796
-0.2564942236308625
-0.416225887163699
-0.6722707203364742
-1.1239218009940952
-1.4307544008792212
-1.0425849355704149
-1.3166311342549468
-1.3049025889067687
-0.9522769910241909
-1.0880244871876
-1.0245002812729238
-0.8782885700233773
-0.6823107743031297
-0.6868570749766482
-0.5783379299278453
-0.7534168006988411
-0.9953881224169795
-0.93229613208344
-1.0103550506281045
-1.6587630775334383
-2.7913132710602504
-2.3229869130550114
-2.5456292299638594
-2.1590321643653128
-1.6901771958868976
-1.4333210505830305
-1.3772220731931235
-0.9846950067576861
-1.2647452174387797
-1.5580668536908966
-4.728430156919477
-19.278991588431463
-11.679792229584374
-55.777849609938755
-57.17550781884578
-27.92537606064995
11.77860669475146
2.2183018948283344
1.753128530653258
1.7994675856317264
1.6257818340856265
1.4734237411211062
1.4603778508265097
1.4076788920888061
1.357880258670786
1.3539775129299862
1.4572571310142848
1.466490529136823
1.3530944388914647
1.3543997480222014
1.357720971109199
1.4236676477170669
1.426385954273022
1.3031028018574304
1.3145095116579264
1.3377570626408577
1.3837755140194021
1.3547629902961476
1.2112353377477534
1.1485083101322693
1.14051396621706
1.104322876206276
1.0374877744017568
1.015554990070677
0.9824272102318045
0.9304646082337029
1.0242491386065202
1.095535855996353
1.087234208189258
1.028072082318587
1.0038800906075833
0.9653162016689766
0.9453438562953215
0.9327002783008559
0.9527146810910432
0.9368064159677135
0.9082466699706149
0.9319605917768985
0.9097194186754993
0.9412950946863881
1.0443350828115716
1.0563928181112467
1.092714829847172
1.1017433030107446
1.1037863161418975
1.1055839919755457
1.0948135000875512
1.1167635939430607
1.1359989417175245
1.0933705173541657
1.1092820888840345
1.086927693583841
1.0896020485834774
1.1547861676210793
1.1152434392121064
1.146857577736166
1.1442931477298801
1.139099572949883
1.1273478833353838
1.1154013654315602
1.0667744084456232
1.0794159057240755
1.108072053305488
1.1116811191460014
1.1104242512077898
1.122631512062082
1.1180387248571515
1.1180599909040196
1.123293224485794
1.1208360277819207
1.1183139167612255
1.1230160039152826
1.122266642478539
1.0976324121078065
1.1202306383721818
1.1304334790252026
1.1236646451535541
1.09676381096376
1.1085863868197974
1.0593102637271543
1.0639169095232262
1.0777989051975512
1.075535614661246
1.082294468262757
1.0864426639672824
1.0702252960211809
1.0574474089894519
1.0356618501176036
1.0345693113529406
1.022808771121517
1.0409467399735906
1.023161195669182
1.0217557829538526
1.0947578284671775
1.091314467224291
1.075063235699523
1.0931983379982426
1.073903186270961
1.0695920087386046
1.0778810591509438
1.074989490283583
1.0787748323407065
1.0655746291316408
1.0505194861762366
1.0479294258256264
1.032466164765955
1.0306527701327137
1.0303599602465614
1.033273246563871
1.0198727618236576
0.9946229837340093
1.002187231183802
1.0513453562855315
1.0345675672659258
1.0212776342850471
1.0321135057618764
1.0548065904888204
1.0475494426546315
1.0474406636778326
1.0489887872963701
1.0507690314849387
1.0487851495460705
1.0306253328163428
1.0393269631765207
1.0376205282515838
1.0301564843587385
1.0268073405470166
1.0412190431966408
1.0415732856927726
1.0413924330021487
1.0381088306352662
1.0346674974926169
1.0170933019630586
1.017767745748975
0.9994634008053125
0.9861995244469579
0.9807315324015207
1.010557211171514
0.9912919745909492
0.9974494372000311
0.9906660659584973
0.9876729798655379
1.0174756854747236
1.0182703903726849
1.0135900154036144
1.0025442268639013
0.9972702912525053
1.014573481492737
0.998450696736642
0.9865579639195975
0.9776997558671994
0.9695080271700999
0.9817790508476459
1.0072585034608963
1.005259942026128
0.9921721064616025
0.9964997989308391
1.0632323958003944
1.0171574730435422
0.9932750405813464
0.9866361504162825
1.0428310403730994
1.0397871668471312
1.0355146811287057
1.0409402753376267
1.0633242604802617
1.090407637765057
1.1111745828930597
1.0654517696715047
1.0664417050150585
1.0634173687755186
1.113473604528116
1.1030282468588188
1.093760438978356
1.0831551951412108
1.0703278347487482
1.0890444264474817
1.0869724835554047
1.0729812179976133
1.0372695951332143
1.0643771089703236
1.0551581097294536
1.0591181574846897
1.0796954629432238
1.09322301996002
1.0887159892069305
1.094569637888769
1.0907478444342795
1.0999076454495729
1.1082489211417845
1.0913367053770011
1.1144796520071931
1.1204018692000477
1.1133129527921166
1.118206024808547
1.1254231214807515
1.1036235392751548
1.1005377689947256
1.0850031670038
1.0862858329699738
1.0749775840623714
1.0708722497919712
1.0883196767718857
1.079781417070113
1.0757782386835317
1.0765978538573815
1.0738736559752875
1.06791893262981
1.0690118379249585
1.0719050179157612
1.0660475216247394
1.0632266051916566
1.0602169205963163
1.054555381957875
1.0543175461398326
1.0542168573966189
1.0532721093588864
1.0524481744681016
1.0532026351305968
1.0514139079814406
1.0513252095089147
1.0514639702385313
1.051167628868614
1.052246393128821
1.0559737887971794
1.0545103093867236
1.0523006772590833
1.0516364876262776
1.0523293524795199
1.0503168406242553
1.050596234648331
1.0528309646577305
1.0528114088109046
1.0521380877741078
1.0520754881923806
1.0521087115233703
1.0508330211785344
1.048572633039487
1.0427354279846595
1.0428210998905638
1.0403049954831456
1.0409711990770274
1.0408508155483884
1.0409985206689496
1.0413292884449645
1.047224086051879
1.047279357012662
1.0481910585720284
1.0517745317920093
1.0495293147423779
1.0511344786516876
1.0494070129349333
1.0466574717411754
1.0453404029741604
1.0464833157148077
1.0475874900695648
1.0490713767577806
1.0516028519954606
1.0568148608213537
1.0568244615528835
1.05577785168669
1.0548582151608439
1.059723382156942
1.0559526184681345
1.0547344119915936
1.0594758861148734
1.0601282785760064
1.0575305535292172
1.0511689413178258
1.0486262876836712
1.0482825214898295
1.0491704707736416
1.0472735237386792
1.0459376865727916
1.0455255390112164
1.0452273636940892
1.0458462518248464
1.0464215941970827
1.0459362260665277
1.0471976749396663
1.046201878411319
1.0430094295926557
1.0420281673504512
1.0410681332771543
1.0417078864642189
1.042123281800142
1.0421250592985172
1.0385902583437174
1.0364716254190418
1.0387357677137457
1.0385549759564987
1.0383858649118392
1.0378597770819065
1.037298318046114
1.0374313207462265
1.0372195661154302
1.0360849995175367
1.0359314035318392
1.0361808149451237
1.0363725726048874
1.0343950185175708
1.0336815889185045
1.0336815889185045
124.61782217298412
124.61782217298412
124.61782217298412
0.07161943803045065
124.61782217298412
1740
0.07161943803045065
Total accuracy sum: 124.61782217298412
Total count of predicted values: 1740
Mean accuracy: 0.07161943803045065
12/12 [==============================] - 0s 2ms/step
[[[-0.4320107 ]
  [-0.43659148]
  [-0.4513216 ]
  [-0.47250247]
  [-0.4975939 ]]
 [[-0.4154573 ]
  [-0.42103332]
  [-0.43620515]
  [-0.4576686 ]
  [-0.4832549 ]]
 [[-0.41655457]
  [-0.41862392]
  [-0.43213618]
  [-0.45377827]
  [-0.48111135]]
 ...
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]]
[[[-0.31002327]
  [-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]]
 [[-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]]
 [[-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]
  [-0.33889113]]
 ...
 [[ 5.59819131]
  [ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]]
 [[ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]]
 [[ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]
  [ 6.01041249]]]
12/12 [==============================] - 0s 3ms/step - loss: nan - mean_squared_error: nan - accuracy: 0.0000e+00 - mean_absolute_error: nan
test loss, test acc: [nan, nan, 0.0, nan]
3/3 [==============================] - 0s 4ms/step - loss: nan - mean_squared_error: nan - accuracy: 0.0000e+00 - mean_absolute_error: nan
test loss, test acc: [nan, nan, 0.0, nan]
12/12 [==============================] - 1s 2ms/step
[[[-0.4492265 ]
  [-0.46291852]
  [-0.47662726]
  [-0.49034113]
  [-0.5047871 ]]
 [[-0.4225905 ]
  [-0.4391544 ]
  [-0.4538427 ]
  [-0.46766597]
  [-0.48169994]]
 [[-0.43872178]
  [-0.431844  ]
  [-0.43000612]
  [-0.4312598 ]
  [-0.43566498]]
 ...
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]
 [[        nan]
  [        nan]
  [        nan]
  [        nan]
  [        nan]]]
[[[-0.31002327]
  [-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]]
 [[-0.26676647]
  [-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]]
 [[-0.22132785]
  [-0.20472602]
  [-0.22859063]
  [-0.272304  ]
  [-0.33889113]]
 ...
 [[ 5.59819131]
  [ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]]
 [[ 5.7613405 ]
  [ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]]
 [[ 6.03063384]
  [ 6.05323221]
  [ 6.0857561 ]
  [ 5.96487804]
  [ 6.01041249]]]
Total accuracy sum: 113.00883121352265
Total count of predicted values: 1740
Mean accuracy: 0.06494760414570268
3/3 [==============================] - 0s 4ms/step - loss: nan - mean_squared_error: nan - accuracy: 0.0000e+00 - mean_absolute_error: nan
test loss, test acc: [nan, nan, 0.0, nan]
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
dict_keys(['loss', 'mean_squared_error', 'accuracy', 'mean_absolute_error', 'val_loss', 'val_mean_squared_error', 'val_accuracy', 'val_mean_absolute_error'])
(353, 10, 4)
3/3 [==============================] - 0s 4ms/step - loss: nan - mean_squared_error: nan - accuracy: 0.0000e+00 - mean_absolute_error: nan
test loss, test acc: [nan, nan, 0.0, nan]
(2, 2, 4)
tf.Tensor([[[25 27]]], shape=(1, 1, 2), dtype=int32)
(2, 2, 4)
tf.Tensor([[[25 27]]], shape=(1, 1, 2), dtype=int32)
tf.Tensor(
[[[-0.7299737 ]
  [-0.30294603]
  [-0.6868937 ]
  [-0.6893585 ]
  [-0.7433964 ]]
 [[-0.30294603]
  [-0.6868937 ]
  [-0.6893585 ]
  [-0.7433964 ]
  [-0.76974356]]
 [[-0.6868937 ]
  [-0.6893585 ]
  [-0.7433964 ]
  [-0.76974356]
  [-0.8064314 ]]
 ...
 [[73.858246  ]
  [26.359459  ]
  [28.300539  ]
  [92.10267   ]
  [44.878933  ]]
 [[26.359459  ]
  [28.300539  ]
  [92.10267   ]
  [44.878933  ]
  [23.57726   ]]
 [[28.300539  ]
  [92.10267   ]
  [44.878933  ]
  [23.57726   ]
  [56.132217  ]]], shape=(353, 5, 1), dtype=float32)
(2, 2, 4)
tf.Tensor([[[25 27]]], shape=(1, 1, 2), dtype=int32)
tf.Tensor(
[[[-7.2997367e-01 -8.8161588e-01 -8.6061519e-01 -8.8415557e-01]
  [-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]]
 [[-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]
  [-7.6974356e-01 -8.8069338e-01 -9.0922779e-01 -8.8856030e-01]]
 [[-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]
  [-7.6974356e-01 -8.8069338e-01 -9.0922779e-01 -8.8856030e-01]
  [-8.0643141e-01 -9.0786791e-01 -8.6792856e-01 -9.2505664e-01]]
 ...
 [[ 7.3858246e+01  4.3805590e+00 -9.7010076e-02  4.8903222e+00]
  [ 2.6359459e+01  1.5682054e-01 -1.4906430e-01 -2.7623951e-02]
  [ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]]
 [[ 2.6359459e+01  1.5682054e-01 -1.4906430e-01 -2.7623951e-02]
  [ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]]
 [[ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]
  [ 5.6132217e+01  1.5901525e+00  1.3101742e+00  1.9572742e+00]]], shape=(353, 5, 4), dtype=float32)
(2, 2, 4)
tf.Tensor([[[25 27]]], shape=(1, 1, 2), dtype=int32)
(353, 10, 4)
tf.Tensor(
[[[-7.2997367e-01 -8.8161588e-01 -8.6061519e-01 -8.8415557e-01]
  [-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]]
 [[-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]
  [-7.6974356e-01 -8.8069338e-01 -9.0922779e-01 -8.8856030e-01]]
 [[-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]
  [-7.6974356e-01 -8.8069338e-01 -9.0922779e-01 -8.8856030e-01]
  [-8.0643141e-01 -9.0786791e-01 -8.6792856e-01 -9.2505664e-01]]
 ...
 [[ 7.3858246e+01  4.3805590e+00 -9.7010076e-02  4.8903222e+00]
  [ 2.6359459e+01  1.5682054e-01 -1.4906430e-01 -2.7623951e-02]
  [ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]]
 [[ 2.6359459e+01  1.5682054e-01 -1.4906430e-01 -2.7623951e-02]
  [ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]]
 [[ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]
  [ 5.6132217e+01  1.5901525e+00  1.3101742e+00  1.9572742e+00]]], shape=(353, 5, 4), dtype=float32)
(2, 2, 4)
tf.Tensor([[[25 27]]], shape=(1, 1, 2), dtype=int32)
(353, 10, 4)
tf.Tensor(
[[[-7.2997367e-01 -8.8161588e-01 -8.6061519e-01 -8.8415557e-01]
  [-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  ...
  [-7.8399724e-01 -9.0164125e-01 -7.9694557e-01 -9.2612636e-01]
  [-7.4493039e-01 -8.8303804e-01 -9.1912240e-01 -8.9781022e-01]
  [-8.1168765e-01 -9.0890574e-01 -9.2772639e-01 -9.2084068e-01]]
 [[-3.0294603e-01 -3.4831071e-01 -8.7653255e-01 -3.6244631e-02]
  [-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  ...
  [-7.4493039e-01 -8.8303804e-01 -9.1912240e-01 -8.9781022e-01]
  [-8.1168765e-01 -9.0890574e-01 -9.2772639e-01 -9.2084068e-01]
  [-5.4898417e-01 -9.0552330e-01 -9.3288881e-01 -9.1096151e-01]]
 [[-6.8689370e-01 -8.7062305e-01 -9.0234458e-01 -9.0485775e-01]
  [-6.8935847e-01 -8.4048891e-01 -8.4297699e-01 -8.5244149e-01]
  [-7.4339640e-01 -8.5317290e-01 -8.5459238e-01 -8.7654167e-01]
  ...
  [-8.1168765e-01 -9.0890574e-01 -9.2772639e-01 -9.2084068e-01]
  [-5.4898417e-01 -9.0552330e-01 -9.3288881e-01 -9.1096151e-01]
  [-7.5596553e-01 -9.0244842e-01 -8.8857818e-01 -9.0926254e-01]]
 ...
 [[ 3.7173630e+01  6.3750625e-01  3.7782321e+00  4.1524041e-01]
  [ 7.2007751e+01  3.6926622e+00  1.1376641e+00  4.1397562e+00]
  [ 4.9924381e+01  3.5088978e+00 -4.3342656e-01  3.3871131e+00]
  ...
  [ 2.8300539e+01  4.5085907e-02  2.1722951e+00 -1.1773217e-01]
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]]
 [[ 7.2007751e+01  3.6926622e+00  1.1376641e+00  4.1397562e+00]
  [ 4.9924381e+01  3.5088978e+00 -4.3342656e-01  3.3871131e+00]
  [ 3.3977432e+01  5.4279888e-01  2.8425467e+00  1.8852258e-01]
  ...
  [ 9.2102669e+01  1.0484300e+00  5.6893957e-01  2.1005538e+00]
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]]
 [[ 4.9924381e+01  3.5088978e+00 -4.3342656e-01  3.3871131e+00]
  [ 3.3977432e+01  5.4279888e-01  2.8425467e+00  1.8852258e-01]
  [ 2.8403154e+01  2.0555794e-01  5.5646372e-01 -1.3969243e-02]
  ...
  [ 4.4878933e+01  1.0552716e+00  1.7042375e+00  1.2505035e+00]
  [ 2.3577259e+01 -4.7549677e-01  1.7618842e+00 -2.3823303e-01]
  [ 5.6132217e+01  1.5901525e+00  1.3101742e+00  1.9572742e+00]]], shape=(348, 10, 4), dtype=float32)
(353, 10, 4)
(353, 10, 4)
3/3 [==============================] - 1s 5ms/step - loss: 2.1469 - mean_squared_error: 9.0632 - accuracy: 0.0000e+00 - mean_absolute_error: 2.6144
